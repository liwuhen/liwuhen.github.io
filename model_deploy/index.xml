<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Model_Deploys on 璇玑</title><link>https://liwuhen.cn/model_deploy/</link><description>Recent content in Model_Deploys on 璇玑</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Sat, 10 Feb 2024 10:17:43 +0000</lastBuildDate><atom:link href="https://liwuhen.cn/model_deploy/index.xml" rel="self" type="application/rss+xml"/><item><title>CUDA篇-Cuda Driver API</title><link>https://liwuhen.cn/model_deploy/cuda_driverapi/</link><pubDate>Sat, 10 Feb 2024 10:17:43 +0000</pubDate><guid>https://liwuhen.cn/model_deploy/cuda_driverapi/</guid><description>一、Driver API CUDA Driver是GPU驱动级底层API随显卡驱动发布，CUDA Driver的头文件与动态库对应于：cuda.h 和 libcuda.so Driver API 主要知识点是 Context 的管理机制 以及 CUDA 系列接口的开发习惯(错误检查方法), 还有内存模型。
参考连接：nvcc, cuda driver,cudatoolkit,cudnn
Driver API是与显卡沟通的底层API，但是人们发现Driver API太过底层，由此引入了Runtime API。从图中可以看出 Runtime API 是基于 Driver API 开发的，我们日常中见到的 cudaMalloc()、cudaMemset()、cudaMemcpy() 都属于 Runtime API。
值得注意的是，cuda.h 是 NVIDIA CUDA Toolkit 中的一部分。CUDA Toolkit 是 NVIDIA 提供的用于开发 GPU 加速应用程序的软件开发工具包，其中包含了用于编译和执行 CUDA 程序的各种库和头文件。而 libcuda.so 是 NVIDIA 显卡驱动安装到系统中时随之安装的一个共享库文件，提供了 CUDA 运行时所需的底层功能和支持。
1.1 context与内存 手动管理的 context，cuCtxCreate()（手动管理，以堆栈方式 push/pop） 自动管理的 context，cuDevicePrimaryCtxRetain（自动管理，runtime api 以此为基础） CPU 内存，称之为 Host Memory。又可以分为 Pageable Memory：可分页内存 + Page-Locked Memory：页锁定内存 GPU 内存，称之为 Device Memory。又可以分为 Global Memory：全局内存 + Shared Memory：共享内存 + 其它多种内存 1.</description></item></channel></rss>